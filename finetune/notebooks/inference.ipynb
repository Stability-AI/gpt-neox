{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2916d5e",
   "metadata": {},
   "source": [
    "- This is a simple inference notebook to see the outputs from the very earry tuned version of StableLM JP models.\n",
    "- The template has two main components:\n",
    "  - 1. instruction - This is usually an actual user input for the model.\n",
    "  - 2. input - This is named `input` but an additional information that comes with the `instruction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2905fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 09:29:00.726141: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 09:29:02.932897: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from datasets import load_dataset\n",
    "import transformers as T\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "645d834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e2807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PROMPT = \"\"\"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
    "\n",
    "### 指示: \n",
    "{instruction}\n",
    "\n",
    "### 入力: \n",
    "{input}\n",
    "\n",
    "### 応答: \"\"\"\n",
    "\n",
    "NO_INPUT_PROMPT = \"\"\"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n",
    "\n",
    "### 指示: \n",
    "{instruction}\n",
    "\n",
    "### 応答: \"\"\"\n",
    "\n",
    "\n",
    "def postprocess_output(output):\n",
    "    output = output\\\n",
    "        .split('### 応答:')[1]\\\n",
    "        .split('###')[0]\\\n",
    "        .split('##')[0]\\\n",
    "        .lstrip(tokenizer.bos_token)\\\n",
    "        .rstrip(tokenizer.eos_token)\\\n",
    "        .replace(\"###\", \"\")\\\n",
    "        .strip()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031791a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class args:\n",
    "    tokenizer_name_or_path: str = \"/PATH/TO/tokenizer/\"\n",
    "    model_name_or_path: str = \"/PATH/TO/CHECKPOINT\"\n",
    "        \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "109f7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name_or_path, use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab177ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc674d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "首都は東京です！\n"
     ]
    }
   ],
   "source": [
    "instruction = \"日本の首都は？\"\n",
    "input_text = NO_INPUT_PROMPT.format(instruction=instruction)\n",
    "token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        min_length=32,\n",
    "        max_length=128,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bad_words_ids=[[tokenizer.unk_token_id]]\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0])\n",
    "print(postprocess_output(output).split('応答:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024dca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ワシントンD.C.\n"
     ]
    }
   ],
   "source": [
    "instruction = \"アメリカの首都は？\"\n",
    "input_text = NO_INPUT_PROMPT.format(instruction=instruction)\n",
    "token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        min_length=32,\n",
    "        max_length=128,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bad_words_ids=[[tokenizer.unk_token_id]]\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0])\n",
    "print(postprocess_output(output).split('応答:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ddb715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "機械学習（ML）は、コンピュータがデータからパターンや特徴を見つけ出し、予測を行うために使用されます。このプロセスは、大量のデータセットを使用して実行されますが、その多くは人間の介入を必要としません。MLの最も一般的な用途には、画像認識、自然言語処理、自動運転車などのアプリケーションがあります。\n"
     ]
    }
   ],
   "source": [
    "instruction = \"人工知能とはどのような技術ですか？\"\n",
    "input_text = NO_INPUT_PROMPT.format(instruction=instruction)\n",
    "token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        min_length=32,\n",
    "        max_length=128,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bad_words_ids=[[tokenizer.unk_token_id]]\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0])\n",
    "print(postprocess_output(output).split('応答:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bfa23b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ニューヨーク・タイムズ紙は、岸田が「日本の選択（10日付）」と題する記事で、中国、ロシア、そして北朝鮮に対抗するため、民主主義国の一員として立ち向かうと説明していることを報じた。\n"
     ]
    }
   ],
   "source": [
    "instruction = \"次の記事を要約してください。\"\n",
    "input_=\"\"\"【ニューヨーク=共同】米誌タイムは10日までに、岸田文雄首相を表紙に掲載した次回号（12日発売）の内容を一部公開した。「日本の選択」と題し、岸田氏が「長年の平和主義を捨て去り、自国を真の軍事大国にすることを望んでいる」と紹介した。\n",
    "記事では岸田氏が19〜21日の主要7カ国首脳会議（G7広島サミット）で、中国やロシア、北朝鮮といった国々に立ち向かうため民主主義国の団結を狙うと説明。防衛費の増額で「世界3位の経済大国に見合った軍事的影響力を持つ国にしようとしている」とした。\n",
    "一方で「核兵器のない世界」を目指す岸田氏の理念と防衛力強化が矛盾するとの意見があると指摘。経済的な結び付きが強い中国との向き合い方など、課題も抱えていると分析した。\n",
    "エマニュエル駐日米大使はツイッターで、岸田氏が外交などで「指導力を発揮している」と述べ、表紙を飾ったことに祝意を示した。岸田氏は4月28日に首相公邸でタイムの取材に応じた。\"\"\"\n",
    "input_text = INPUT_PROMPT.format(instruction=instruction, input=input_)\n",
    "token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        min_length=32,\n",
    "        max_length=512,\n",
    "        temperature=0.4,\n",
    "        do_sample=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        # repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bad_words_ids=[[tokenizer.unk_token_id]]\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0])\n",
    "print(postprocess_output(output).split('応答:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10254571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私はAIアシスタントのAlexaです。よろしくお願いします！\n"
     ]
    }
   ],
   "source": [
    "instruction = \"あなたはAIアシスタントです。AIアシスタントとしてふるまってください。そのうえで自己紹介をお願いします。\"\n",
    "input_text = NO_INPUT_PROMPT.format(instruction=instruction)\n",
    "token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        min_length=32,\n",
    "        max_length=128,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bad_words_ids=[[tokenizer.unk_token_id]]\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0])\n",
    "print(postprocess_output(output).split('応答:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c34182c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私はAIが人間よりも優れているとは考えていません。しかし、AIの進歩により多くのことが可能になることは確かだと思います。例えば、機械学習やディープラーニングなどの技術を使用して、より良い意思決定を行うことができます。また、自動運転車などの人工知能システムも開発されています。\n"
     ]
    }
   ],
   "source": [
    "instruction = \"AIについてどう思いますか？\"\n",
    "input_text = NO_INPUT_PROMPT.format(instruction=instruction)\n",
    "token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        min_length=32,\n",
    "        max_length=128,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bad_words_ids=[[tokenizer.unk_token_id]]\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0])\n",
    "print(postprocess_output(output).split('応答:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8bc301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "横須賀市は神奈川県三浦半島にある都市で、東京湾の入り口に位置しています。\n"
     ]
    }
   ],
   "source": [
    "instruction = \"横須賀はどんなところ？\"\n",
    "input_text = NO_INPUT_PROMPT.format(instruction=instruction)\n",
    "token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        min_length=32,\n",
    "        max_length=128,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bad_words_ids=[[tokenizer.unk_token_id]]\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0])\n",
    "print(postprocess_output(output).split('応答:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05c40129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "横須賀市は神奈川県南部に位置し、東京湾の入り口にあたる場所にあります。市内には約120万人の人々が暮らしており、人口密度は全国第3位となっています。また、日本有数の米軍基地である横須賀基地は、日本の国防の最重要拠点であり、国内最大の軍事都市でもあります。\n"
     ]
    }
   ],
   "source": [
    "instruction = \"横須賀はどんなところ？\"\n",
    "input_text = NO_INPUT_PROMPT.format(instruction=instruction)\n",
    "token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        min_length=32,\n",
    "        max_length=128,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bad_words_ids=[[tokenizer.unk_token_id]]\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0])\n",
    "print(postprocess_output(output).split('応答:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5143a5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ジョン・F・ケネディ大統領です！\n"
     ]
    }
   ],
   "source": [
    "instruction = \"今のアメリカの大統領は誰ですか？\"\n",
    "input_text = NO_INPUT_PROMPT.format(instruction=instruction)\n",
    "token_ids = tokenizer.encode(input_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        token_ids.to(model.device),\n",
    "        min_length=32,\n",
    "        max_length=128,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        bad_words_ids=[[tokenizer.unk_token_id]]\n",
    "    )\n",
    "\n",
    "output = tokenizer.decode(output_ids.tolist()[0])\n",
    "print(postprocess_output(output).split('応答:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc604b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
